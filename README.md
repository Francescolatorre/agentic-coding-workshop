# ğŸ§  Agentic Coding Workshop â€“ Game Results Tracker (2h Edition)

## Overview

Teams compete to **build a game results tracking app** using **AI-powered coding tools** and the **agentic coding mindset**.

**Duration**: 2 hours
**Participants**: ~20 mx ai engineers (5 teams)
**Goal**: Build a working MVP with quality, design, and smart AI usage

---

## ğŸ•’ Schedule

| Time          | Duration | Activity                                                                                                           |
| ------------- | -------- | ------------------------------------------------------------------------------------------------------------------ |
| 00:00 â€“ 00:15 | 15 min   | **Introduction to Agentic Coding**  <br>â€¢ What is agentic coding?  <br>â€¢ Tools & mindset  <br>â€¢ Challenge overview |
| 00:15 â€“ 00:20 | 5 min    | **Team Formation** <br>Balance AI experience levels                                                                |
| 00:20 â€“ 01:20 | 60 min   | **Coding Sprint** <br>Build the MVP using the starter template                                                     |
| 01:20 â€“ 01:30 | 10 min   | **Break + Review** <br>Progress check & demo prep                                                                  |
| 01:30 â€“ 01:55 | 25 min   | **Team Presentations** <br>5 min per team                                                                          |
| 01:55 â€“ 02:00 | 5 min    | **Judging & Wrap-Up** <br>Winner announcement & feedback                                                           |

---

## ğŸ‘¥ Team Formation

Each team should include mixed experience levels:

| Level       | Description                       |
| ----------- | --------------------------------- |
| ğŸŸ¢ Beginner | Rarely uses AI tools              |
| ğŸŸ¡ Casual   | Uses ChatGPT occasionally         |
| ğŸ”µ Regular  | Uses Copilot/Cursor daily         |
| ğŸ”¶ Advanced | Builds with multi-agent workflows |

---

## ğŸ¯ The Challenge

**Objective:** Build a mini-platform to track game results and rankings.
See [`SPEC.md`](SPEC.md) for details.

### MVP Requirements

* User creation (username)
* Game creation (with image upload)
* Result submission
* Scoreboard view

### Bonus

* Persistent data
* Creative UI/UX
* Smart AI-driven additions

---

## ğŸ§© Evaluation Criteria

| Category       | Weight | Description                                                      |
| -------------- | ------ | ---------------------------------------------------------------- |
| Functional     | 50%    | MVP works and core flow complete                                 |
| Non-Functional | 50%    | Clean code, thoughtful design, innovation, and agentic use of AI |

---

## ğŸ¤ Presentation (5 min per team)

1. **Demo** â€“ Show your running app
2. **Architecture** â€“ Use AI to summarize or visualize
3. **AI Techniques** â€“ How you used agentic coding
4. **Unique Twist** â€“ What makes your solution special

---

## âš™ï¸ Setup & Resources

* **Starter Template:** `hackathon-starter/`
  Stack: Next.js 15, TypeScript, Tailwind

  ```bash
  cd hackathon-starter
  npm install
  npm run dev
  ```
* **Docs:**

  * [`SETUP.md`](SETUP.md) â†’ AI tool setup (Codex, Claude Code, RooCode)
  * [`HANDOUT.md`](HANDOUT.md) â†’ Troubleshooting & hints

---

## ğŸ† Awards

Prizes for the top teams based on total score.
Focus on **quality + creativity + agentic AI collaboration**, not just speed.
